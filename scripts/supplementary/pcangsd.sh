#!/bin/bash
#SBATCH --job-name=PCAngsd         
#SBATCH --ntasks=1 
#SBATCH --cpus-per-task=4
#SBATCH --mem=80GB 
#SBATCH --time=48:00:00
#SBATCH --mail-user=alexander.piper@agriculture.vic.gov.au
#SBATCH --mail-type=ALL
#SBATCH --account=pathogens
#SBATCH --export=none
#SBATCH --output=%x.%j.out
#SBATCH --error=%x.%j.out

#--------------------------------------------------------------------------------
#-                                  HEADER		                                -
#--------------------------------------------------------------------------------

# Welcome to the insect SkimSeq Pipeline
# Developed by Alexander Piper 
# Contact: alexander.piper@agriculture.vic.gov.au

# This script applies PCAngsd to Genotype likelihood files generated by ANGSD

if [ -z "$SLURM_ARRAY_TASK_COUNT" ]; then 
  echo SLURM_ARRAY_TASK_COUNT unset; 
  echo You must launch this job as an array
  echo see https://slurm.schedmd.com/job_array.html
  echo for info on how to run arrays
  exit 1
fi

Index=pcangsd_job_index.txt

# Check sequence index file exists
if [[ ! -f "${Index}" ]]; then
  echo "Error sequence index file ${Index} does not exist"
  exit 1
fi

#--------------------------------------------------------------------------------
#-                                  Parse Inputs                                -
#--------------------------------------------------------------------------------
# Default to empty inputs
beagle=""

# Function: Print a help message.
usage() {                                 
  echo "Usage: $0 [ -R Reference Genome ] [ -O output directory ] " 1>&2 
}
# Function: Exit with error.
exit_abnormal() {                         
  usage
  exit 1
}

# Get input options
OPTIND=1
while getopts ":B:S:O:e:t" options; do       
  # use silent error checking;
  case "${options}" in
    B)                             
      beagle=${OPTARG}
	  # Test if exists
	  if [ ! -f "$beagle" ] ; then  
        echo "Error: -B ${beagle} doesnt exist"
        exit_abnormal
        exit 1
      fi
	  echo beagle=${beagle}	  
      ;;
    S)
	  sitelist=${OPTARG}
	  # Test if not empty
	  if [[ $sitelist ]]; then
		  # test if exists
		  if [ ! -f "$sitelist" ] ; then  
			echo "Error: -S ${sitelist} doesnt exist"
			exit_abnormal
			exit 1
		  fi
		echo sitelist=${sitelist}
	  fi
      ;;
     e)
      eigen=${OPTARG}
	  manual_eigen='true'
    ;;
    O)
      outdir=${OPTARG}
      echo outdir=${outdir}
      ;;
    t)
	  echo "-t has been set, subsampling all fastqs for testing purposes" >&2
	  test_run='true'
    ;;
	:) 
	# Exit If expected argument omitted
      echo "Error: -${OPTARG} requires an argument."
      exit_abnormal 
	  ;;
    *) 
	# Exit If unknown (any other) option
      exit_abnormal
      ;;
  esac
done
shift $((OPTIND -1))

#--------------------------------------------------------------------------------
#-                                    Preparation                               -
#--------------------------------------------------------------------------------
# Read input params
bamlist=$(sed -n ${SLURM_ARRAY_TASK_ID}p ${Index})

# Get sample name from beagle file
Sample=$(basename ${beagle} .beagle.gz)
echo Sample=${Sample}

#set outdir file name
outname=$(echo $Sample $(echo $(basename ${bamlist}) | sed 's/bamlist_//g' | sed 's/.txt//g') $(basename ${sitelist} | sed 's/.sites.*$//g' ) | sed 's/ /-/g' )

# Make directories for outdirs
mkdir -p ${outdir}/${outname}

# Goto tmp
cd $TMPDIR
tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
cd ${tmp_dir}
pwd

# Copy data files to temp and decompress
cp ${beagle} .
cp ${sitelist} .
cp ${bamlist} .

ls 
pigz -p ${SLURM_CPUS_PER_TASK} -d *.gz

#--------------------------------------------------------------------------------
#-                                  TEST	                                    -
#--------------------------------------------------------------------------------
# if -t is set, all fastqs will be subsampled to make the run fastQC
if [[ "$test_run" = true ]]; then
    # For quick testing - subsample input to just first chromosome and 1000 sitees
    echo subsampling to first chr/contig only
    chr1=$(cat ${Sample}.beagle | head -n 2 | tail -n 1 | awk -F '\t' '{print $1}' | awk -F '_' '{print $1}')
    cat ${Sample}.beagle | head -n 1  > ${Sample}.test.beagle
    cat ${Sample}.beagle | grep ${chr1} | head -1000 >> ${Sample}.test.beagle
    mv ${Sample}.test.beagle ${Sample}.beagle
fi

#--------------------------------------------------------------------------------
#-                           		 Prune samples                              -
#--------------------------------------------------------------------------------

# Subset beagle to only the samples within bamlist
cat ${Sample}.beagle | head -1 | tr "\t" "\n" > header

# Get file to search
printf  'marker\nallele1\nallele2\n' > search.txt
cat ${bamlist} | sed 's/.bam//g' >> search.txt
 
# Get the rows that arent in the bamlist
grep -vf search.txt header | sort | uniq > to_remove

#Check if any samples need removing
if grep -q '[^[:space:]]' to_remove; then
	echo "Subsetting beagle file to match bamlist"	
	# Get the index of the rows to remove and put in a variable
	index_rem=$(grep -nFf to_remove header | cut -d : -f 1 | tr "\n" ","| sed '$s/,$//')

	echo index_rem is ${index_rem}

	# Remove those that arent in bamlist cut complement removes them
	cat ${Sample}.beagle | cut --complement -f${index_rem} > ${Sample}.subset.beagle
	mv ${Sample}.subset.beagle  ${Sample}.beagle 

	echo $(expr $( cat ${Sample}.beagle | head -1 | tr "\t" "\n" | uniq | wc -l) - 3) samples remaining after subsetting

else 
	echo "no samples to remove"
fi

# Clean up
rm header
rm search.txt
rm to_remove

#--------------------------------------------------------------------------------
#-                           		Prune SNPs                                  -
#--------------------------------------------------------------------------------

if [ -n "$sitelist" ]; then
	echo "Subsetting to only those sites within sitelist: ${sitelist}"
    cat $(basename ${sitelist} .gz) | tr ":" "_" > sites_to_keep
	cat ${Sample}.beagle | head -n 1  > ${Sample}.subset.beagle
	cat ${Sample}.beagle | grep -Fwf sites_to_keep >> ${Sample}.subset.beagle
	mv ${Sample}.subset.beagle ${Sample}.beagle
else 
	echo "no sites to remove"
fi

#--------------------------------------------------------------------------------
#-                              Run PCAngsd with MAP test                       -
#--------------------------------------------------------------------------------
#Load Modules
module purge
module load PCAngsd/20220922-foss-2021b 
module load evalAdmix/20221126-GCCcore-11.2.0 
module load Python/3.9.6-GCCcore-11.2.0

# Make convert.py to turn npy files into txt for evaladmix
echo 'import numpy as np
F = np.load("tempF.npy") # Read in ancestral population frequencies file
np.savetxt("F.txt", F, newline="\n")
quit()' > convert.py

echo 'import numpy as np
F = np.load("tmp.npy") # Read in ancestral population frequencies file
np.savetxt("weights.txt", F, newline="\n")
quit()' > convert_weights.py

# First do a run using MAP test to determine optimal eigenvectors
echo "Choosing optimal number of eigenvectors from MAP test"
mkdir optim

# Run 1 - estimate inbreeding and kinship, filter for minmaf - PCANGSD requires zipped beagle
pigz ${Sample}.beagle -p ${SLURM_CPUS_PER_TASK} --fast
pcangsd -b ${Sample}.beagle.gz -o ${Sample}.pcangsd --threads ${SLURM_CPUS_PER_TASK} \
--minMaf 0.01 \
--sites_save \
--inbreedSites \
--inbreedSamples 
pigz -d ${Sample}.beagle.gz -p ${SLURM_CPUS_PER_TASK}

# Get a list of sites used from Run 1
cat ${Sample}.beagle | cut -f 1 | tail -n +2 > ${Sample}.temp
echo $(cat ${Sample}.temp | wc -l) sites as input to run1
grep -Fn '1' ${Sample}.pcangsd.sites | grep -Eo '^[^:]+' > positions.txt
echo $(cat positions.txt | wc -l) sites in positions file from run1
awk 'NR==FNR{ pos[$1]; next }FNR in pos' positions.txt ${Sample}.temp > ${Sample}.temp2
mv -f ${Sample}.temp2 optim/${outname}_optim.pcangsd.sites1
pigz optim/${outname}_optim.pcangsd.sites1 -p ${SLURM_CPUS_PER_TASK}

# Subset beagle to only the sites kept within run 1
cat ${Sample}.beagle | head -n 1  > ${Sample}.subset.beagle
cat ${Sample}.beagle | cut -f 1 | tail -n +2 > ${Sample}.temp
grep -Fn '1' ${Sample}.pcangsd.sites | grep -Eo '^[^:]+' > positions.txt
awk 'NR==FNR{ pos[$1]; next }FNR in pos' positions.txt ${Sample}.temp > to_keep
echo $(cat to_keep | wc -l) sites kept from run1
cat ${Sample}.beagle | grep -Fwf to_keep >> ${Sample}.subset.beagle
echo $(cat ${Sample}.subset.beagle | cut -f 1 | tail -n +2 | wc -l) sites kept in beagle file from run1

# Run 2 estimate covariance matrix, admixture, kinship and selection after HWE filter
pigz ${Sample}.subset.beagle  -p ${SLURM_CPUS_PER_TASK} --fast
pcangsd -b ${Sample}.subset.beagle.gz -o optim/${outname}_optim.pcangsd --threads ${SLURM_CPUS_PER_TASK} \
--minMaf 0 \
--admix \
--sites_save \
--inbreedSamples \
--pcadapt \
--selection \
--snp_weights \
--maf_save \
--hwe ${Sample}.pcangsd.lrt.sites.npy \
--hwe_tole 1e-6 \
--tree 
pigz -d ${Sample}.subset.beagle.gz -p ${SLURM_CPUS_PER_TASK}

# Subset again to only the sites kept within run 2
mv -f optim/${outname}_optim.pcangsd.sites ./${Sample}.pcangsd.sites
cat ${Sample}.subset.beagle | head -n 1  > ${Sample}.subset2.beagle
cat ${Sample}.subset.beagle | cut -f 1 | tail -n +2 > ${Sample}.temp
echo $(cat ${Sample}.temp | wc -l) sites as input to run2
grep -Fn '1' ${Sample}.pcangsd.sites | grep -Eo '^[^:]+' > positions.txt
echo $(cat positions.txt | wc -l) sites in positions file from run2
awk 'NR==FNR{ pos[$1]; next }FNR in pos' positions.txt ${Sample}.temp > to_keep
echo $(cat to_keep | wc -l) sites kept from run2
cat ${Sample}.subset.beagle | grep -Fwf to_keep >> ${Sample}.subset2.beagle
echo $(cat ${Sample}.subset2.beagle | cut -f 1 | tail -n +2 | wc -l) sites kept in beagle file from run2

# Count how many sites in the snp weights
cp optim/${outname}_optim.pcangsd.weights.npy tmp.npy
python convert_weights.py
echo $(cat weights.txt | wc -l) sites in weights file

# Convert admix files from numpy to txt
admixF=$(ls optim | grep '.F.npy')
admixQ=$(ls optim | grep '.Q')
cp optim/${admixF} ./tempF.npy
cp optim/${admixQ} ./Q.txt
python convert.py

# Run EvalAdmix
pigz ${Sample}.subset2.beagle -p ${SLURM_CPUS_PER_TASK} --fast
evalAdmix -beagle ${Sample}.subset2.beagle.gz -fname F.txt -qname Q.txt -minMaf 0 -misTol 0 -P ${SLURM_CPUS_PER_TASK} -o optim/${outname}_optim.corres.txt
pigz -d ${Sample}.subset2.beagle.gz -p ${SLURM_CPUS_PER_TASK}

# Get a list of sites used for run2
cat ${Sample}.subset2.beagle | cut -f 1 | tail -n +2 > ${Sample}.temp
mv -f ${Sample}.temp optim/${outname}_optim.pcangsd.sites2
pigz optim/${outname}_optim.pcangsd.sites2 -p ${SLURM_CPUS_PER_TASK}

# Get a list of samples used
cat ${Sample}.subset2.beagle | head -1 | cut --complement -f 1,2,3 | tr "\t" "\n" | uniq > ${Sample}_bams.txt
cp ${Sample}_bams.txt optim

#Copy outdir folder and remove temp files
cp -r optim $(realpath ${outdir}/${outname}/)/.
rm *.pcangsd.*
rm ${Sample}.subset.beagle
rm ${Sample}.subset2.beagle

#--------------------------------------------------------------------------------
#-                      Run PCAngsd over multiple eigenvectors                  -
#--------------------------------------------------------------------------------

if [[ "$manual_eigen" = true ]]; then
    
    #Iterate over multiple eigenvectors
    #e should be K - 1
    for e in $(echo $eigen | tr ',' ' '); do
        k=$(expr ${e} + 1)
        minpop=2
        if [ "$k" -lt "$minpop" ]; then
            k=2 
        fi
        echo "Runing PCAngsd using $e eigenvectors and $k populations"

        mkdir e${e}
        # Run 1 - estimate inbreeding and kinship, filter for minmaf
        pigz ${Sample}.beagle -p ${SLURM_CPUS_PER_TASK} --fast
        pcangsd -b ${Sample}.beagle.gz -o ${Sample}.pcangsd --threads ${SLURM_CPUS_PER_TASK} \
        -e ${e} \
        --minMaf 0.01 \
        --sites_save \
        --inbreedSites \
        --inbreedSamples 
        pigz -d ${Sample}.beagle.gz -p ${SLURM_CPUS_PER_TASK}

        # Get a list of sites used from Run 1
        cat ${Sample}.beagle | cut -f 1 | tail -n +2 > ${Sample}.temp
        echo $(cat ${Sample}.temp | wc -l) sites as input to run1
        grep -Fn '1' ${Sample}.pcangsd.sites | grep -Eo '^[^:]+' > positions.txt
        echo $(cat positions.txt | wc -l) sites in positions file from run1
        awk 'NR==FNR{ pos[$1]; next }FNR in pos' positions.txt ${Sample}.temp > ${Sample}.temp2
        mv -f ${Sample}.temp2 e${e}/${outname}_e${e}.pcangsd.sites1
        pigz e${e}/${outname}_e${e}.pcangsd.sites1 -p ${SLURM_CPUS_PER_TASK}

        # Subset beagle to only the sites kept within run 1
        cat ${Sample}.beagle | head -n 1  > ${Sample}.subset.beagle
        cat ${Sample}.beagle | cut -f 1 | tail -n +2 > ${Sample}.temp
        grep -Fn '1' ${Sample}.pcangsd.sites | grep -Eo '^[^:]+' > positions.txt
        awk 'NR==FNR{ pos[$1]; next }FNR in pos' positions.txt ${Sample}.temp > to_keep
        echo $(cat to_keep | wc -l) sites kept from run1
        cat ${Sample}.beagle | grep -Fwf to_keep >> ${Sample}.subset.beagle
        echo $(cat ${Sample}.subset.beagle | cut -f 1 | tail -n +2 | wc -l) sites kept in beagle file from run1

        # Run 2 estimate covariance matrix, admixture, kinship and selection after HWE filter
        pigz ${Sample}.subset.beagle -p ${SLURM_CPUS_PER_TASK} --fast
        pcangsd -b ${Sample}.subset.beagle.gz -o e${e}/${outname}_e${e}.pcangsd --threads ${SLURM_CPUS_PER_TASK} \
        -e ${e} \
        --minMaf 0 \
        --admix \
        --admix_K ${k} \
        --inbreedSamples \
        --sites_save \
        --pcadapt \
        --selection \
        --snp_weights \
        --maf_save \
        --hwe ${Sample}.pcangsd.lrt.sites.npy \
        --hwe_tole 1e-6 \
        --tree 
        pigz -d ${Sample}.subset.beagle.gz -p ${SLURM_CPUS_PER_TASK}

        # Subset again to only the sites kept within run 2
        mv -f e${e}/${outname}_e${e}.pcangsd.sites ./${Sample}.pcangsd.sites
        cat ${Sample}.subset.beagle | head -n 1  > ${Sample}.subset2.beagle
        cat ${Sample}.subset.beagle | cut -f 1 | tail -n +2 > ${Sample}.temp
        echo $(cat ${Sample}.temp | wc -l) sites as input to run2
        grep -Fn '1' ${Sample}.pcangsd.sites | grep -Eo '^[^:]+' > positions.txt
        echo $(cat positions.txt | wc -l) sites in positions file from run2
        awk 'NR==FNR{ pos[$1]; next }FNR in pos' positions.txt ${Sample}.temp > to_keep
        echo $(cat to_keep | wc -l) sites kept from run2
        cat ${Sample}.subset.beagle | grep -Fwf to_keep >> ${Sample}.subset2.beagle
        echo $(cat ${Sample}.subset2.beagle | cut -f 1 | tail -n +2 | wc -l) sites kept in beagle file from run2
        
        # Count how many sites in the snp weights
        cp e${e}/${outname}_e${e}.pcangsd.weights.npy tmp.npy
        python convert_weights.py
        echo $(cat weights.txt | wc -l) sites in weights file    
        
        # Convert admix files from numpy to txt
        admixF=$(ls e${e} | grep '.F.npy')
        admixQ=$(ls e${e} | grep '.Q.npy')
        cp e${e}/${admixF} ./tempF.npy
        cp e${e}/${admixQ} ./tempQ.npy
        python convert.py

        # Run EvalAdmix
        pigz ${Sample}.subset2.beagle -p ${SLURM_CPUS_PER_TASK} --fast
        evalAdmix -beagle ${Sample}.subset2.beagle.gz -fname F.txt -qname Q.txt -minMaf 0 -misTol 0 -P ${SLURM_CPUS_PER_TASK} -o e${e}/${outname}_e${e}.corres.txt
        pigz -d ${Sample}.subset2.beagle.gz -p ${SLURM_CPUS_PER_TASK}

        # Get a list of sites used for run2
        cat ${Sample}.subset2.beagle | cut -f 1 | tail -n +2 > ${Sample}.temp
        mv -f ${Sample}.temp e${e}/${outname}_e${e}.pcangsd.sites2
        pigz e${e}/${outname}_e${e}.pcangsd.sites2 -p ${SLURM_CPUS_PER_TASK}

        # Get a list of samples used
        cat ${Sample}.subset2.beagle | head -1 | cut --complement -f 1,2,3 | tr "\t" "\n" | uniq > ${Sample}_bams.txt
        cp ${Sample}_bams.txt e${e}

        #Copy outdir folder and remove temp files
        cp -r e${e} $(realpath ${outdir}/${outname}/)/.
        rm *.pcangsd.*
        rm ${Sample}.subset.beagle
        rm ${Sample}.subset2.beagle
    done

fi

# outdir useful job stats
/usr/local/bin/showJobStats.scr
