#!/bin/bash
#SBATCH --job-name=NGSadmix         
#SBATCH --ntasks=1 
#SBATCH --cpus-per-task=8
#SBATCH --mem=100GB 
#SBATCH --time=72:00:00
#SBATCH --account=pathogens
#SBATCH --export=none
#SBATCH --output=%x.%j.out
#SBATCH --error=%x.%j.out


#--mail-user=alexander.piper@agriculture.vic.gov.au
#--mail-type=ALL

#--------------------------------------------------------------------------------
#-                                  HEADER		                                -
#--------------------------------------------------------------------------------

# Welcome to the insect SkimSeq Pipeline
# Developed by Alexander Piper 
# Contact: alexander.piper@agriculture.vic.gov.au

# This script applies NGSadmix to Genotype likelihood files generated by ANGSD

if [ -z "$SLURM_ARRAY_TASK_COUNT" ]; then 
  echo SLURM_ARRAY_TASK_COUNT unset; 
  echo You must launch this job as an array
  echo see https://slurm.schedmd.com/job_array.html
  echo for info on how to run arrays
  exit 1
fi

Index=ngsadmix_job_index.txt

# Check sequence index file exists
if [[ ! -f "${Index}" ]]; then
  echo "Error sequence index file ${Index} does not exist"
  exit 1
fi

#--------------------------------------------------------------------------------
#-                                  Parse Inputs                                -
#--------------------------------------------------------------------------------
# Default to empty inputs
beagle=""

# Function: Print a help message.
usage() {                                 
  echo "Usage: $0 [ -R Reference Genome ] [ -O output directory ] " 1>&2 
}
# Function: Exit with error.
exit_abnormal() {                         
  usage
  exit 1
}

# Get input options
OPTIND=1
while getopts ":B:S:O:k:s:n:t" options; do       
  # use silent error checking;
  case "${options}" in
    B)                             
      beagle=${OPTARG}
	  # Test if exists
	  if [ ! -f "$beagle" ] ; then  
        echo "Error: -B ${beagle} doesnt exist"
        exit_abnormal
        exit 1
      fi
	  echo beagle=${beagle}	  
      ;;
    S)
	  sitelist=${OPTARG}
	  # Test if not empty
	  if [[ $sitelist ]]; then
		  # test if exists
		  if [ ! -f "$sitelist" ] ; then  
			echo "Error: -S ${sitelist} doesnt exist"
			exit_abnormal
			exit 1
		  fi
		echo sitelist=${sitelist}
	  fi
      ;;
     k)
      clusters=${OPTARG}
      echo clusters=${clusters}
    ;;
    s)
      seed=${OPTARG}
      if [[ ! $seed ]]; then
          echo "seed not provided, setting random seed"
          seed=$RANDOM
      fi
      echo seed=${seed}
    ;; 
    n)
     # Repeat for this many reps
     num=${OPTARG}
     if [[ ! $num ]]; then
          echo "num not provided, running a single iteration only"
          num=1
     fi
     echo num=${num}
    ;;
    O)
      outdir=${OPTARG}
      echo outdir=${outdir}
      ;;
    t)
	  echo "-t has been set, subsampling all fastqs for testing purposes" >&2
	  test_run='true'
    ;;
	:) 
	# Exit If expected argument omitted
      echo "Error: -${OPTARG} requires an argument."
      exit_abnormal 
	  ;;
    *) 
	# Exit If unknown (any other) option
      exit_abnormal
      ;;
  esac
done
shift $((OPTIND -1))

#--------------------------------------------------------------------------------
#-                                    Preparation                               -
#--------------------------------------------------------------------------------
# Read input params
bamlist=$(sed -n ${SLURM_ARRAY_TASK_ID}p ${Index})

# Get sample name from beagle file
Sample=$(basename ${beagle} .beagle.gz)
echo Sample=${Sample}

#set outdir file name
outname=$(echo $Sample $(echo $(basename ${bamlist}) | sed 's/bamlist_//g' | sed 's/manifest_//g'| sed 's/.txt//g') $(basename ${sitelist} | sed 's/.sites.*$//g' ) | sed 's/ /-/g' )

# Make directories for outdirs
mkdir -p ${outdir}/${outname}

# Goto tmp
cd $TMPDIR
tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
cd ${tmp_dir}
pwd

#--------------------------------------------------------------------------------
#-                                  TEST	                                    -
#--------------------------------------------------------------------------------
# if -t is set, all fastqs will be subsampled
if [[ "$test_run" = true ]]; then
    # For quick testing - subsample input to just first 10000 sitees
    echo subsampling to first 10000 sites only
    #chr1=$(pigz -p ${SLURM_CPUS_PER_TASK} -cd ${beagle} | head -n 2 | tail -n 1 | awk -F '\t' '{print $1}' | awk -F '_' '{print $1}')
    pigz -p ${SLURM_CPUS_PER_TASK} -cd ${beagle} | head -n 1  > ${Sample}.test.beagle
    pigz -p ${SLURM_CPUS_PER_TASK} -cd ${beagle} | head -10000 >> ${Sample}.test.beagle
    mv ${Sample}.test.beagle ${Sample}.beagle
else 
    pigz -p ${SLURM_CPUS_PER_TASK} -cd ${beagle} > ${Sample}.beagle
fi

#--------------------------------------------------------------------------------
#-                           		 Prune samples                              -
#--------------------------------------------------------------------------------

# Subset beagle to only the samples within bamlist
cat ${Sample}.beagle | head -1 | tr "\t" "\n" > header

# Get file to search
printf  'marker\nallele1\nallele2\n' > search.txt
cat ${bamlist} | sed 's/.bam//g' >> search.txt
 
# Get the rows that arent in the bamlist
grep -vf search.txt header | sort | uniq > to_remove

#Check if any samples need removing
if grep -q '[^[:space:]]' to_remove; then
	echo "Subsetting beagle file to match bamlist"	
	# Get the index of the rows to remove and put in a variable
	index_rem=$(grep -nFf to_remove header | cut -d : -f 1 | tr "\n" ","| sed '$s/,$//')

	echo index_rem is ${index_rem}

	# Remove those that arent in bamlist cut complement removes them
	cat ${Sample}.beagle | cut --complement -f${index_rem} > ${Sample}.subset.beagle
	mv ${Sample}.subset.beagle  ${Sample}.beagle 

	echo $(expr $( cat ${Sample}.beagle | head -1 | tr "\t" "\n" | uniq | wc -l) - 3) samples remaining after subsetting

else 
	echo "no samples to remove"
fi

# Clean up
rm header
rm search.txt
rm to_remove

#--------------------------------------------------------------------------------
#-                           		Prune SNPs                                  -
#--------------------------------------------------------------------------------

if [ -n "$sitelist" ]; then
	echo "Subsetting to only those sites within sitelist: ${sitelist}"
    pigz -p ${SLURM_CPUS_PER_TASK} -cd ${sitelist} | tr ":" "_" > sites_to_keep
	cat ${Sample}.beagle | head -n 1  > ${Sample}.subset.beagle
	cat ${Sample}.beagle | grep -Fwf sites_to_keep >> ${Sample}.subset.beagle
	mv ${Sample}.subset.beagle ${Sample}.beagle
else 
	echo "no sites to remove"
fi

#--------------------------------------------------------------------------------
#-                            Run NGSadmix until convergence                    -
#--------------------------------------------------------------------------------
#Load Modules
module purge
module load HTSlib/1.15-GCC-11.2.0
module load evalAdmix/20221126-GCCcore-11.2.0 
module load Python/3.9.6-GCCcore-11.2.0
module load R/4.2.0-foss-2021b

pigz ${Sample}.beagle -p ${SLURM_CPUS_PER_TASK}

#Iterate over multiple values of k
for k in $(echo $clusters | tr ',' ' '); do
    echo "Runing NGSadmix using $k populations"

    mkdir k${k}
    rm k${k}/${outname}_k${k}.likes
    touch k${k}/${outname}_k${k}.likes
    # Repeat until convergence
    # Modified from https://github.com/KHanghoj/leopardpaper/blob/master/main_analysis/ngsadmix/NGSadmixConv.sh
    for f in `seq ${num}`; do
        echo running ngsadmix k=$k iteration $f
        
        # Create a seed for each iteration, seed will be the startign seed + the iteration
        iter_seed=$((${seed}+${f}-1))
        
        # Run ngsadmix
        /home/ap0y/angsd/angsd/misc/NGSadmix -likes ${Sample}.beagle.gz -K ${k} -o k${k}/${outname}_k${k}_s${seed} -P ${SLURM_CPUS_PER_TASK} -misTol 0.05 -minMaf 0 -minLrt 0 -minInd 0 -seed ${iter_seed} -printInfo 1
        
        # Get likelihoods
        grep "like=" k${k}/${outname}_k${k}_s${seed}.log | cut -f2 -d " " | cut -f2 -d "=" >> k${k}/${outname}_k${k}.likes
        
        #Check for convergence. 
        #CONV=`Rscript --vanilla -e "r<-read.table('k${k}/${outname}_k${k}.likes');r<-r[order(-r[,1]),];cat(sum(r[1]-r<3),'\n')"` 
        #if [ $CONV -gt 2 ]  #-gt 2 = greater than 2
        #    then
        #    echo ngsadmix k=$k reached convergence on iteration $f
        #    cp k${k}/${outname}_k${k}_s${seed}.qopt k${k}/${outname}_k${k}_s${seed}.qopt_conv
        #    cp k${k}/${outname}_k${k}_s${seed}.fopt.gz k${k}/${outname}_k${k}_s${seed}.fopt_conv.gz
        #    cp k${k}/${outname}_k${k}_s${seed}.log k${k}/${outname}_k${k}_s${seed}.log_conv
        #    break
        #fi
        
        # Run EvalAdmix 
        evalAdmix -beagle ${Sample}.beagle.gz -fname k${k}/${outname}_k${k}_s${seed}.fopt.gz -qname k${k}/${outname}_k${k}_s${seed}.qopt -misTol 0.05 -minMaf 0 -P 4 -o k${k}/${outname}_k${k}_s${seed}.corres.txt
    done
    
    # Get a list of samples used
    zcat ${Sample}.beagle.gz | head -1 | cut --complement -f 1,2,3 | tr "\t" "\n" | uniq > k${k}/${outname}_k${k}_bams.txt
    
    # Zip any filter files to save space
    pigz -p ${SLURM_CPUS_PER_TASK} k${k}/*.filter
    
    #Copy outdir folder and remove temp files
    cp -r k${k} ${outdir}/${outname}/.
done

# Remove temporary directory 
rm -rf ${tmp_dir}/*

# outdir useful job stats
/usr/local/bin/showJobStats.scr
